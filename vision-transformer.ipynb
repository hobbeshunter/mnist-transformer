{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(0.5, 1.0)])\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "image_size=28\n",
    "num_classes=10\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure = plt.figure(figsize=(10, 8))\n",
    "cols, rows = 5, 5\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.numpy().squeeze(), cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_ratio = 0.9\n",
    "train_data_nr = int(len(train_data) * train_valid_ratio)\n",
    "valid_data_nr = len(train_data) - train_data_nr\n",
    "\n",
    "train_data, valid_data = torch.utils.data.random_split(\n",
    "    train_data, [train_data_nr, valid_data_nr], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "loaders = {\n",
    "    'train': torch.utils.data.DataLoader(train_data,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=2),\n",
    "    'valid': torch.utils.data.DataLoader(valid_data,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=2),\n",
    "    'test': torch.utils.data.DataLoader(test_data,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=1)\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def train_model(loaders, num_epochs: int, model: torch.nn.Module, loss_func, optimizer: torch.optim.Optimizer, writer=None, lr_scheduler=None):\n",
    "    last_valid_loss = float(\"Inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        model.train()\n",
    "        sum_loss_train = 0\n",
    "        for images, labels in loaders['train']:\n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            if torch.cuda.is_available():\n",
    "                images, labels = images.cuda(\n",
    "                    non_blocking=True), labels.cuda(non_blocking=True)\n",
    "\n",
    "            b_x = Variable(images)\n",
    "            b_y = Variable(labels)\n",
    "\n",
    "            output = model(b_x)\n",
    "            loss = loss_func(output, b_y)\n",
    "\n",
    "            # clear gradients for this training step\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # backpropagation, compute gradients\n",
    "            loss.backward()\n",
    "            # apply gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            sum_loss_train += loss.item()\n",
    "\n",
    "        if writer:\n",
    "            writer.add_scalar(\"AvgTrainLoss/Epoch\",\n",
    "                              sum_loss_train / len(loaders['train']), epoch)\n",
    "            writer.flush()\n",
    "\n",
    "        model.eval()\n",
    "        sum_loss_valid = 0\n",
    "        for i, (images, labels) in enumerate(loaders['valid']):\n",
    "            if torch.cuda.is_available():\n",
    "                images, labels = images.cuda(\n",
    "                    non_blocking=True), labels.cuda(non_blocking=True)\n",
    "            b_x = Variable(images)\n",
    "            b_y = Variable(labels)\n",
    "\n",
    "            output = model(b_x)\n",
    "            loss = loss_func(output, b_y)\n",
    "            sum_loss_valid += loss.item()\n",
    "\n",
    "        last_valid_loss = sum_loss_valid / len(loaders['valid'])\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1:2d}/{num_epochs}], TrainLoss: {sum_loss_train / len(loaders['train']):.4f}, ValidLoss: {last_valid_loss:.4f}, LearningRate: {optimizer.param_groups[0]['lr']:.5f}\")\n",
    "\n",
    "        if writer:\n",
    "            writer.add_scalar(\"AvgValidLoss/Epoch\",\n",
    "                              last_valid_loss, epoch)\n",
    "            writer.flush()\n",
    "\n",
    "        if lr_scheduler:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "    return last_valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import GrayscaleVisionTransformer, ConvStemConfig\n",
    "\n",
    "\n",
    "#transformer hyper prams\n",
    "patch_size=7\n",
    "num_layers=6\n",
    "num_heads=8\n",
    "hidden_dim=num_heads * 8\n",
    "mlp_dim=128\n",
    "dropout=0.5\n",
    "attention_dropout=0.5\n",
    "\n",
    "model = GrayscaleVisionTransformer(image_size=image_size, patch_size=patch_size, num_layers=num_layers, num_heads=num_heads,\n",
    "                                   hidden_dim=hidden_dim, mlp_dim=mlp_dim, dropout=dropout, attention_dropout=attention_dropout, num_classes=num_classes)\n",
    "# conv_stem_configs=[ConvStemConfig(out_channels=32, kernel_size=5, padding=2, stride=1), ConvStemConfig(out_channels=32, kernel_size=patch_size, stride=patch_size)]\n",
    "\n",
    "number_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "number_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or CNN\n",
    "\n",
    "from CNN import CNN\n",
    "\n",
    "hidden_dim = [32, 32, 64]\n",
    "dropout = 0.5\n",
    "\n",
    "model = CNN(image_size=image_size, hidden_dim=hidden_dim,\n",
    "            dropout=dropout, num_classes=num_classes)\n",
    "\n",
    "number_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "number_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Transformer\n",
    "learning_rate = 0.0025\n",
    "epochs = 40\n",
    "weight_decay = 0\n",
    "scheduler_gamma = 0.96\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "    loss_func = loss_func.cuda()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer=optimizer, gamma=scheduler_gamma)\n",
    "writer = SummaryWriter()\n",
    "images, labels = next(iter(loaders['train']))\n",
    "if torch.cuda.is_available():\n",
    "    images = images.cuda()\n",
    "# writer.add_graph(model, images)\n",
    "valid_loss = train_model(loaders, epochs, model,\n",
    "                         loss_func, optimizer, writer, lr_scheduler)\n",
    "writer.add_hparams({'learning_rate': learning_rate, 'batch_size': batch_size, 'patch_size': patch_size, 'num_layers': num_layers, 'num_heads': num_heads,\n",
    "                   'hidden_dim': hidden_dim, 'mlp_dim': mlp_dim, 'dropout': dropout, 'attention_dropout': attention_dropout, 'weight_decay': weight_decay, 'scheduler_gamma': scheduler_gamma}, {'number_params': number_params, 'valid_loss': valid_loss})\n",
    "writer.close()\n",
    "torch.save(model.state_dict(), 'saved_model_transformer.pth')\n",
    "torch.cuda.empty_cache()\n",
    "del images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or train cnn\n",
    "\n",
    "learning_rate = 0.002\n",
    "epochs = 40\n",
    "weight_decay = 1e-3\n",
    "scheduler_gamma = 0.96\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "    loss_func = loss_func.cuda()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer=optimizer, gamma=scheduler_gamma)\n",
    "writer = SummaryWriter()\n",
    "images, labels = next(iter(loaders['train']))\n",
    "if torch.cuda.is_available():\n",
    "    images = images.cuda()\n",
    "# writer.add_graph(model, images)\n",
    "valid_loss = train_model(loaders, epochs, model,\n",
    "                         loss_func, optimizer, writer, lr_scheduler)\n",
    "writer.add_hparams({'learning_rate': learning_rate, 'batch_size': batch_size, 'dropout': dropout, 'weight_decay': weight_decay,\n",
    "                   'scheduler_gamma': scheduler_gamma}, {'number_params': number_params, 'valid_loss': valid_loss})\n",
    "writer.close()\n",
    "torch.save(model.state_dict(), 'saved_model_cnn.pth')\n",
    "torch.cuda.empty_cache()\n",
    "del images, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or load transformer\n",
    "from transformer import GrayscaleVisionTransformer\n",
    "model = model = GrayscaleVisionTransformer(image_size=image_size, patch_size=patch_size, num_layers=num_layers, num_heads=num_heads,\n",
    "                                           hidden_dim=hidden_dim, mlp_dim=mlp_dim, dropout=dropout, attention_dropout=attention_dropout, num_classes=num_classes)\n",
    "if torch.cuda.is_available():\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "model.load_state_dict(torch.load('saved_model_transformer.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or load cnn\n",
    "from CNN import CNN\n",
    "model = CNN()\n",
    "if torch.cuda.is_available():\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "model.load_state_dict(torch.load('saved_model_cnn.pth'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def images_to_probs(model, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = model(images)\n",
    "\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.cpu().numpy())\n",
    "    return preds, [torch.nn.functional.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    for idx in np.arange(6*6):\n",
    "        ax = fig.add_subplot(6, 6, idx+1, xticks=[], yticks=[])\n",
    "        img = images[idx]\n",
    "        img = img.mean(dim=0)\n",
    "        img = img / 2 + 0.5\n",
    "        plt.imshow(img.cpu().numpy().squeeze(), cmap=\"gray\")\n",
    "        ax.set_title(f\"pred: {preds[idx]}, prob: { probs[idx] * 100.0:.1f}%, gt: {labels[idx]}\",\n",
    "                     color=(\"green\" if preds[idx] == labels[idx].item() else \"red\"))\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def accuracy(output: torch.Tensor, target: torch.Tensor, topk=(1,)) -> List[torch.FloatTensor]:\n",
    "    \"\"\"\n",
    "    Computes the accuracy over the k top predictions for the specified values of k\n",
    "    In top-5 accuracy you give yourself credit for having the right answer\n",
    "    if the right answer appears in your top five guesses.\n",
    "\n",
    "    ref:\n",
    "    - https://pytorch.org/docs/stable/generated/torch.topk.html\n",
    "    - https://discuss.pytorch.org/t/imagenet-example-accuracy-calculation/7840\n",
    "    - https://gist.github.com/weiaicunzai/2a5ae6eac6712c70bde0630f3e76b77b\n",
    "    - https://discuss.pytorch.org/t/top-k-error-calculation/48815/2\n",
    "    - https://stackoverflow.com/questions/59474987/how-to-get-top-k-accuracy-in-semantic-segmentation-using-pytorch\n",
    "\n",
    "    :param output: output is the prediction of the model e.g. scores, logits, raw y_pred before normalization or getting classes\n",
    "    :param target: target is the truth\n",
    "    :param topk: tuple of topk's to compute e.g. (1, 2, 5) computes top 1, top 2 and top 5.\n",
    "    e.g. in top 2 it means you get a +1 if your models's top 2 predictions are in the right label.\n",
    "    So if your model predicts cat, dog (0, 1) and the true label was bird (3) you get zero\n",
    "    but if it were either cat or dog you'd accumulate +1 for that example.\n",
    "    :return: list of topk accuracy [top1st, top2nd, ...] depending on your topk input\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "        _, y_pred = output.topk(k=maxk, dim=1)\n",
    "        y_pred = y_pred.t()\n",
    "\n",
    "        target_reshaped = target.view(1, -1).expand_as(y_pred)\n",
    "        correct = (y_pred == target_reshaped)\n",
    "        list_topk_accs = []\n",
    "        for k in topk:\n",
    "            ind_which_topk_matched_truth = correct[:k]\n",
    "            flattened_indicator_which_topk_matched_truth = ind_which_topk_matched_truth.reshape(\n",
    "                -1).float()\n",
    "            tot_correct_topk = flattened_indicator_which_topk_matched_truth.float().sum(dim=0,\n",
    "                                                                                        keepdim=True)\n",
    "            topk_acc = tot_correct_topk / batch_size\n",
    "            list_topk_accs.append(topk_acc)\n",
    "        return list_topk_accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc top1 and top5 accuracy\n",
    "predictions = []\n",
    "labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels_batch in loaders['test']:\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda(non_blocking=True)\n",
    "        pred = model(images)\n",
    "        predictions.append(pred.cpu())\n",
    "        labels.append(labels_batch)\n",
    "    predictions = torch.cat(predictions)\n",
    "    labels = torch.cat(labels)\n",
    "acc = accuracy(predictions, labels, (1, 5))\n",
    "torch.cuda.empty_cache()\n",
    "acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some images + predictions\n",
    "writer = SummaryWriter()\n",
    "images, labels = next(iter(loaders['test']))\n",
    "if torch.cuda.is_available():\n",
    "    images, labels = images.cuda(), labels.cuda()\n",
    "writer.add_figure('predictions vs. actuals',\n",
    "                plot_classes_preds(model, images, labels))\n",
    "writer.flush()\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot wrong predictions\n",
    "writer = SummaryWriter()\n",
    "images_wrong = []\n",
    "predictions_wrong = []\n",
    "labels_wrong = []\n",
    "for images, labels in iter(loaders['test']):\n",
    "    if torch.cuda.is_available():\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "    predictions, probs = images_to_probs(model, images)\n",
    "\n",
    "    for pred, label, image in zip(predictions, labels.cpu(), images.cpu()):\n",
    "        if pred != label.item():\n",
    "            images_wrong.append(image)\n",
    "            predictions_wrong.append(pred)\n",
    "            labels_wrong.append(label)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "for idx in np.arange(6*6):\n",
    "    ax = fig.add_subplot(6, 6, idx+1, xticks=[], yticks=[])\n",
    "    img = images_wrong[idx]\n",
    "    img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5\n",
    "    plt.imshow(img.cpu().numpy().squeeze(), cmap=\"gray\")\n",
    "    ax.set_title(f\"pred: {predictions_wrong[idx]}, gt: {labels_wrong[idx]}\",\n",
    "                    color=\"red\")\n",
    "plt.tight_layout()\n",
    "\n",
    "writer.add_figure('wrong predictions', fig)\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "4785ca6bc74ab1bf8923b15666a66fb5b8bd787fdd462bdcc152b9c2405ab7dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
